1) Installation of Hadoop

>>Open Ubuntu
	
	sudo su
	sudo apt update -y
	sudo apt install openjdk-11-jdk -y
	cd /usr/local
	sudo wget https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
	sudo tar -xvzf hadoop-3.3.6.tar.gz
	sudo mv hadoop-3.3.6 hadoop 
	sudo nano ~/.bashrc
	>>paste in bash
		export HADOOP_HOME=/usr/local/hadoop 
		export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 
		export JAVA_HOME=$(readlink -f /usr/bin/java | sed "s:/bin/java::") 
		export PATH=$PATH:$JAVA_HOME/bin
	>> ctrl+x
	source ~/.bashrc 
	hadoop version
	
if command apt shows error ,use yum instead of apt
--------+------

CODING: -  
• sudo su 
• sudo  yum update -y 
• sudo yum install java-11-openjdk-devel -y or sudo yum install java-1.8.0-amazon-corretto
devel -y 
• java -version 
• cd /usr/local/ 
• sudo wget https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz 
• sudo tar -xvzf hadoop-3.3.6.tar.gz 
• sudo mv hadoop-3.3.6 hadoop 
• sudo nano ~/.bashrc 
o # Hadoop variables 
o export HADOOP_HOME=/usr/local/hadoop 
o export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 
o # Java variables 
o export JAVA_HOME=$(readlink -f /usr/bin/java | sed "s:/bin/java::") 
o export PATH=$PATH:$JAVA_HOME/bin 
• source ~/.bashrc 
• hadoop version 
• Configure core-site.xml 
o sudo nano $HADOOP_HOME/etc/hadoop/core-site.xml 
o <configuration> 
o    
o       
o       
o    
o    
o       
o       
o       
o    
<property> 
<name>fs.defaultFS</name> 
<value>hdfs://localhost:9000</value> 
</property> 
<property> 
<name>hadoop.tmp.dir</name> 
<value>/usr/local/hadoop/tmp</value> 
<description>Temporary directory for Hadoop</description> 
</property> 
o </configuration> 
• Configure hdfs-site.xml 
o sudo nano $HADOOP_HOME/etc/hadoop/hdfs-site.xml 
o <configuration> 
o    
o       
o       
<property> 
<name>dfs.replication</name> 
<value>1</value> <!-- Since this is a single-node setup --> 
</property> 
o    
o    
o       
o       
o    
o    
o       
o       
o    
<property> 
<name>dfs.namenode.name.dir</name> 
<value>file:///usr/local/hadoop/hdfs/namenode</value> 
</property> 
<property> 
<name>dfs.datanode.data.dir</name> 
<value>file:///usr/local/hadoop/hdfs/datanode</value> 
</property> 
o </configuration> 
• Create the mapred-site.xml[If the mapred-site.xml.template is not present] 
o sudo nano /usr/local/hadoop/etc/hadoop/mapred-site.xml 
o <configuration> 
o    
o       
o       
o    
<property> 
<name>mapreduce.framework.name</name> 
<value>yarn</value> 
</property> 
o </configuration> 
• Configure yarn-site.xml 
o sudo nano $HADOOP_HOME/etc/hadoop/yarn-site.xml 
o <configuration> 
o    
o       
o       
o    
o    
o       
o       
o    
<property> 
<name>yarn.nodemanager.aux-services</name> 
<value>mapreduce_shuffle</value> 
</property> 
<property> 
<name>yarn.resourcemanager.resource-tracker.address</name> 
<value>localhost:8025</value> 
</property> 
<property> 
o    
o       
o       
o    
o    
o       
o       
o    
<name>yarn.resourcemanager.scheduler.address</name> 
<value>localhost:8030</value> 
</property> 
<property> 
<name>yarn.resourcemanager.address</name> 
<value>localhost:8050</value> 
</property> 
o </configuration> 
• Set Up Hadoop Directories 
o sudo mkdir -p /usr/local/hadoop/hdfs/namenode 
o sudo mkdir -p /usr/local/hadoop/hdfs/datanode 
o sudo mkdir -p /usr/local/hadoop/tmp 
• Format the HDFS Filesystem 
o hdfs namenode -format 
• Start Hadoop Services(As Non - Root User) 
o start-dfs.sh 
o start-yarn.sh 
o Jps 
• Access the Hadoop Web Interfaces 
o NameNode: http://localhost:9870/ (shows the HDFS overview)
 ResourceManager: http://localhost:8088/ (shows the YARN overview) 
o LocalHost - 127.0.0.1 or public DNS :- 3.117.182.16

